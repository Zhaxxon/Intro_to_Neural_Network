{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"6lesson_segmentation.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"cells":[{"cell_type":"markdown","metadata":{"id":"at3nuxAQIOjM","colab_type":"text"},"source":["# Введение в искусственные нейронные сети\n","# Урок 6. Сегментация"]},{"cell_type":"markdown","metadata":{"id":"_OcYcWvQIOjP","colab_type":"text"},"source":["## Содержание методического пособия:\n","\n","\n","<ol>\n","<li>Что такое сегментация изображения</li>\n","<li>Виды архитектур для сегментации изображений</li>\n","<li>Практический пример сегментации</li>\n","</ol>"]},{"cell_type":"markdown","metadata":{"id":"d0zowYO2IOjS","colab_type":"text"},"source":["## Что такое сегментация изображения"]},{"cell_type":"markdown","metadata":{"id":"Q76fNKjdIOjT","colab_type":"text"},"source":["В компьютерное зрении есть несколько основых видов задач. Это такие задачи как классификация, сегментация и детектирование объектов.\n","\n","До сих пор задачи в области комп. зрения с которыми мы сталкивались относились к задаче классификации. Эта задача подразумевает получения предсказания от нейронной сети названия класса объекта, который ей представлен на изображении. \n","\n","Решение данной задачи интересно для академических кругов, для поиска новых архитектур и определенного практического применения, однако для продвинутого комп. зрения как правило требуется не только знать, что за объект находиться на изображении, но и где он находиться, какой этот объект формы и т.д. Данные задачи и призваны решить нейронные сети для сегментации и нейронные сети для дектирования объектов. \n","\n","\n","В этом уроке мы познакомимся с задачей сегментации. Сегментация изображения подразумевает отнесение каждого пикселя изображения к определенному классу. Т.е. по сути мы получаем маску изображения."]},{"cell_type":"markdown","metadata":{"id":"DWF6yp7nIOjV","colab_type":"text"},"source":["![1.png](attachment:1.png)"]},{"cell_type":"markdown","metadata":{"id":"ATC5uV86IOjW","colab_type":"text"},"source":["Источник изображения: Image Segmentation Using Deep Learning: A Survey. Shervin Minaee и др. 15 Jan 2020"]},{"cell_type":"markdown","metadata":{"id":"hRRyGeDPIOjX","colab_type":"text"},"source":["Нейронные сети для сегментирования изображений находят широкое применение в беспилотном транспорте, \"умном\" видеонаблюдении, медицине и др. областях.\n","\n","\n","Подобного рода нейронные сети состоят как правило из части, которая ответственна за восприятие объектов на изображении и части, которая ответственна за определение контуров изображения. Данные нейросети относительно тяжеловестны с точки зрения вычеслительных затрат, однако в научных кругах ведется поиск более легковесных решений.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dHdz6mqeIOjY","colab_type":"text"},"source":["Для тренировки нейронных сетей решающих задачу сегментирования применяются свои специальные датасеты, в которых размечена маска изображения, например, такие как PASCAL Visual Object Classes или COCO(Common Objects in Context). Датасетов для сегментации меньше и они сложнее в составлении. Поэтому существует распространенная практика использования предобученнной нейронной сети, например, на ImageNet, в качестве части отвественной за восприятие объектов. Затем уже нейронная сеть доубучаестся на размеченных масках с помощью специальных датасетов."]},{"cell_type":"markdown","metadata":{"id":"Gnf7uFo9IOja","colab_type":"text"},"source":["На сегодняшний день существует огромное множество архитектр для сегментации изобржаней, в данном мет. пособие мы разберем основные."]},{"cell_type":"markdown","metadata":{"id":"dVjiO0BaIOjb","colab_type":"text"},"source":["## Виды архитектур для сегментации изображений\n"]},{"cell_type":"markdown","metadata":{"id":"xXjseI9RIOjc","colab_type":"text"},"source":["Как ранее уже было упомянуто архитектур для решения задачи сегментации существует много и продолжают появляться новые. Мы рассмотрим такие архитектуры как FCN (fully convolutional network), SegNet, U-net, Mask-RCNN. Данные архитектуры отражают основные вехи в эволюции архитектур нейронных сетей для решения задачи сегментации. Также мы рассмотрим архитектуру Autoencoder, которую полезно рассмотреть как вводную часть к большинтсву архитектур в области сегментации изображениий."]},{"cell_type":"markdown","metadata":{"id":"A-gBb5bbIOjh","colab_type":"text"},"source":["![2.png](attachment:2.png)"]},{"cell_type":"markdown","metadata":{"id":"Z_TG7YpwIOjj","colab_type":"text"},"source":["Источник изображения: Image Segmentation Using Deep Learning: A Survey. Shervin Minaee и др. 15 Jan 2020"]},{"cell_type":"markdown","metadata":{"id":"gYVYSAB_IOjk","colab_type":"text"},"source":["### FCN (fully convolutional network)"]},{"cell_type":"markdown","metadata":{"id":"y3NIXrUPIOjm","colab_type":"text"},"source":["Данная архитектура появилась в 2014 г., буквально через несколько лет после того, как глубокое обучение получило широкое распространение."]},{"cell_type":"markdown","metadata":{"id":"i12BouXHIOjn","colab_type":"text"},"source":["FCN в отличие от обычной CNN не имеет на конце полносвязных слоев, вместо этого на конце нейронной сети располагается модуль, который позволяет увеличить то представление изображения, которое имеют обычные CNN перед передачей данных в полносвязные слои."]},{"cell_type":"markdown","metadata":{"id":"KgTmpPVZIOjo","colab_type":"text"},"source":["![3.png](attachment:3.png)"]},{"cell_type":"markdown","metadata":{"id":"SfR0RdKbIOjv","colab_type":"text"},"source":["Источник изображения: Image Segmentation Using Deep Learning: A Survey. Shervin Minaee и др. 15 Jan 2020"]},{"cell_type":"markdown","metadata":{"id":"v9xZf119IOjy","colab_type":"text"},"source":["Данный подход позволил превзойти предыдущие подходы в этой области, которые базировались не на глубоком обучении, однако и он имел свои изъяны."]},{"cell_type":"markdown","metadata":{"id":"K2UhZufyIOjz","colab_type":"text"},"source":["### Autoencoder\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6QIHuDOuIOj0","colab_type":"text"},"source":["Прежде чем, мы разберерм архитектуру SegNet, давайте посмотрим на Autoencoder. Данная архитектура предствляет из себя набор слоев, которые сжимают входящие данные во все более маленькое представление, а также слоев, которые разжимают затем данные. \n","\n","Если после такой процедуры сжатия и разжатия, удается получить на выходе изначальные данные, значит в центральных слоях данной архитектуры располагается сжатое представление данных. Отбросив вторую, разжимающую данные, часть, можно использовать сжатые данные для различных целей."]},{"cell_type":"markdown","metadata":{"id":"Rr1gO74WIOj2","colab_type":"text"},"source":["![0.png](attachment:0.png)"]},{"cell_type":"markdown","metadata":{"id":"AJzOFFA3IOj9","colab_type":"text"},"source":["Источник изображения: https://pythonmachinelearning.pro/all-about-autoencoders/"]},{"cell_type":"markdown","metadata":{"id":"GhboXZHsIOj_","colab_type":"text"},"source":["### SegNet"]},{"cell_type":"markdown","metadata":{"id":"1monGeF6IOkA","colab_type":"text"},"source":["SegNet появилась в 2015 г. Данная архитектура состоит из конволюционной и деконволюционной части. Она отчасти повторяет собой архитектуру Autoencoder, где есть кодирующая и декодирующая часть. \n","\n","Декодирующая часть в SegNet позволяет сделать более плавное разворачивание изображения после того как отработала конвулюционная(сверточная) часть архитектуры. Благодаря этому границы объектов на изображение определяются более корректно.\n","\n","Стоит отметить, что в качестве конвулюционной(сверточной) части могут использоваться различные предтренерованные нейронные сети для решения задач классификации, например различные модификации VGG и ResNet."]},{"cell_type":"markdown","metadata":{"id":"IuinKU4fIOkB","colab_type":"text"},"source":["![4.png](attachment:4.png)"]},{"cell_type":"markdown","metadata":{"id":"QuiZ7SCPIOkD","colab_type":"text"},"source":["Источник изображения: Image Segmentation Using Deep Learning: A Survey. Shervin Minaee и др. 15 Jan 2020"]},{"cell_type":"markdown","metadata":{"id":"fgO6CSCTIOkE","colab_type":"text"},"source":["### U-Net"]},{"cell_type":"markdown","metadata":{"id":"D9MiMfz6IOkF","colab_type":"text"},"source":["U-net появился в 2015 г. для решения медицинский задач. Данная архитектура и ее модификации являются одним из основых практических инструментов для решения современных задач сегментации изображений. Данная архитектура отличается более высокой степенью точности сегментирования, достачной для работы с мед. снимками, картами где располагаются множество мелких объектов и др. задач.\n","\n","\n","U-net также как и SegNet берет input и реконструирует output как сегментированную карту изображения. Однако в данной архитектуре используются skip connection, похожие на те, что помогли решить проблему исчезающего градиента в задача классификации(ResNet архитектура). Данные skip connections позволяют сигналу не только проходить строго, сначала по нисходящей лестницы слоев, а потом по восходящей лестнице апсемплинга(увеличение маленькой репрезентации изображения в полноценную карту), но и также перескакивать между слоями одного уровня, что в частности решает проблему дублирования функций слоев и улучшает эффективность обучения. "]},{"cell_type":"markdown","metadata":{"id":"Pxryls7kIOkH","colab_type":"text"},"source":["![5.png](attachment:5.png)"]},{"cell_type":"markdown","metadata":{"id":"rveUMfcdIOkI","colab_type":"text"},"source":["Источник изображения: Image Segmentation Using Deep Learning: A Survey. Shervin Minaee и др. 15 Jan 2020"]},{"cell_type":"markdown","metadata":{"id":"hoK5F_b9IOkJ","colab_type":"text"},"source":["### FPN (The Feature Pyramid Network)"]},{"cell_type":"markdown","metadata":{"id":"e1Dbbud8IOkK","colab_type":"text"},"source":["Данная архитектура появилась в 2017 г. Визуально, данная архитектура похожа на пирамиду. Она может применяться как для задач детектирования объектов, так и для задач сегментации изображений. FPN во многом похожа на U-Net, однако есть одно важное нововведение - предсказания снимаются не только с самой высокой части апсемплинга, но и на каждой ступени начинающейся в фазе декодирования. Это позволяет совершать детекцию на разных масштабах восстанавливаемого изображения, что положительно сказываеться на точности сегментирования."]},{"cell_type":"markdown","metadata":{"id":"dvlr5e6XIOkL","colab_type":"text"},"source":["![6.png](attachment:6.png)"]},{"cell_type":"markdown","metadata":{"id":"HopRNrgQIOkN","colab_type":"text"},"source":["Источник изображения: Feature Pyramid Networks for Object Detection, Tsung-Yi Lin и др. 19 апр. 2017 г."]},{"cell_type":"markdown","metadata":{"id":"9TBsRZbkIOkO","colab_type":"text"},"source":["### Mask R-CNN"]},{"cell_type":"markdown","metadata":{"id":"4IAjNwTmIOkV","colab_type":"text"},"source":["Данная архитектура появилась в 2018 г. и является надстройкой над Faster R-CNN, одной из лучших архитектур в сфере object detection. Мы не будем касаться сейчас этой архитектуры, она будет рассмотрена в следующем уроке.\n","\n","В Mask R-CNN, также как и в ранее рассмотренных архитектурах, используется часть с энкодером (например ResNet101), но в нее добавлен модуль Region Proposal Network (RPN) из сферы object detection, который позволяет эффективно находить места на изображение где могут находиться объекты, после чего Mask R-CNN генерирует сегментационную маску."]},{"cell_type":"markdown","metadata":{"id":"mJ24voSjIOkW","colab_type":"text"},"source":["![7.png](attachment:7.png)"]},{"cell_type":"markdown","metadata":{"id":"PhRS1RhMIOkX","colab_type":"text"},"source":["Источник изображения: Mask R-CNN, Kaiming He и др. 24 янв. 2018 г."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cZCM65CBt1CJ"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"C6LXpA8cIOkZ","colab_type":"text"},"source":["## Практический пример сегментации"]},{"cell_type":"markdown","metadata":{"id":"y2SqHKYaIOka","colab_type":"text"},"source":["В качестве практики попробуем сегментирвать изображение домашних животных из датасета Oxford-IIIT Pet Dataset, с использованием модифицированной версии U-Net. Данный пример тестировался и корректно работал при составлении мет. пособия на python 3.7.7 и tensorflow 2.1.0. Также может понадобиться установить модуль для python под названием tensorflow-datasets."]},{"cell_type":"code","metadata":{"id":"_ILw7W1hIOke","colab_type":"code","colab":{}},"source":["##### Copyright 2019 The TensorFlow Authors.\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\");"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","colab_type":"code","id":"JOgMcEajtkmg","colab":{}},"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MQmKthrSBCld","colab":{}},"source":["!pip install git+https://github.com/tensorflow/examples.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YQX7R4bhZy5h","colab":{}},"source":["try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"g87--n2AtyO_","colab":{}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","from tensorflow_examples.models.pix2pix import pix2pix\n","\n","import tensorflow_datasets as tfds\n","tfds.disable_progress_bar()\n","\n","from IPython.display import clear_output\n","import matplotlib.pyplot as plt\n","\n","\n","import tensorflow as tf\n","tf.config.experimental.set_visible_devices([], 'GPU')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oWe0_rQM4JbC"},"source":["## Загрузка датасета Oxford-IIIT Pets\n","\n","Датасет является стандартным датасетом для TensorFlow, однако как упомяналось выше возможно необходимо будет установить модуль tensorflow-datasets для python."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"40ITeStwDwZb","colab":{}},"source":["dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rJcVdj_U4vzf"},"source":["Следующий код выполнит простую аугументацию данных посредством переворота изображений. В дополнение изображение будет нормализовано к 0 и 1. Пиксели сегментационной маски будут помечены {1, 2, 3}, но для удобства из данного цифрового ряда будет вычтено по 1 и в итоге получиться {0, 1, 2}"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FD60EbcAQqov","colab":{}},"source":["def normalize(input_image, input_mask):\n","  input_image = tf.cast(input_image, tf.float32) / 255.0\n","  input_mask -= 1\n","  return input_image, input_mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2NPlCnBXQwb1","colab":{}},"source":["@tf.function\n","def load_image_train(datapoint):\n","  input_image = tf.image.resize(datapoint['image'], (128, 128))\n","  input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))\n","\n","  if tf.random.uniform(()) > 0.5:\n","    input_image = tf.image.flip_left_right(input_image)\n","    input_mask = tf.image.flip_left_right(input_mask)\n","\n","  input_image, input_mask = normalize(input_image, input_mask)\n","\n","  return input_image, input_mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Zf0S67hJRp3D","colab":{}},"source":["def load_image_test(datapoint):\n","  input_image = tf.image.resize(datapoint['image'], (128, 128))\n","  input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))\n","\n","  input_image, input_mask = normalize(input_image, input_mask)\n","\n","  return input_image, input_mask"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"65-qHTjX5VZh"},"source":["Датасет уже содержит необходимые тестовый и тренеровочный сплиты, поэтому давайте использовать их."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yHwj2-8SaQli","colab":{}},"source":["TRAIN_LENGTH = info.splits['train'].num_examples\n","BATCH_SIZE = 64\n","BUFFER_SIZE = 1000\n","STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"39fYScNz9lmo","colab":{}},"source":["train = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","test = dataset['test'].map(load_image_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DeFwFDN6EVoI","colab":{}},"source":["train_dataset = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n","train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","test_dataset = test.batch(BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Xa3gMAE_9qNa"},"source":["Давайте посмотрим на пример  изображения из датасета и соотвествующую ему маску из датасета."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3N2RPAAW9q4W","colab":{}},"source":["def display(display_list):\n","  plt.figure(figsize=(15, 15))\n","\n","  title = ['Input Image', 'True Mask', 'Predicted Mask']\n","\n","  for i in range(len(display_list)):\n","    plt.subplot(1, len(display_list), i+1)\n","    plt.title(title[i])\n","    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n","    plt.axis('off')\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"a6u_Rblkteqb","colab":{}},"source":["for image, mask in train.take(1):\n","  sample_image, sample_mask = image, mask\n","display([sample_image, sample_mask])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FAOe93FRMk3w"},"source":["## Определение модели\n","\n","Будем использовать модифицированный U-Net. В качестве энкодера будет использоваться предтренированный MobileNetV2.\n","Декодером будет апсемпл блок уже имплементированный в TensorFlow examples [Pix2pix tutorial](https://github.com/tensorflow/examples/blob/master/tensorflow_examples/models/pix2pix/pix2pix.py).\n","\n","Причина по который будет испольваться три канала заключается в том что у нас 3 возможных лейбла на каждый пиксель. Можно это воспринимать как классиификацию где кажедый пиксель будет принадлежать одному из трех классов."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"c6iB4iMvMkX9","colab":{}},"source":["OUTPUT_CHANNELS = 3"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"W4mQle3lthit"},"source":["Как упоминалось ранее энкодером будет предтренированный MobileNetV2, который подготовлен и готов к использованию - [tf.keras.applications](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/applications). Энкодер состоит из определенных аутпутов из средних слоев модели. Обратите внимание энкодр не будет участвовать в процессе тренировкие модели."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"liCeLH0ctjq7","colab":{}},"source":["base_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)\n","\n","# Use the activations of these layers\n","layer_names = [\n","    'block_1_expand_relu',   # 64x64\n","    'block_3_expand_relu',   # 32x32\n","    'block_6_expand_relu',   # 16x16\n","    'block_13_expand_relu',  # 8x8\n","    'block_16_project',      # 4x4\n","]\n","layers = [base_model.get_layer(name).output for name in layer_names]\n","\n","# Create the feature extraction model\n","down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n","\n","down_stack.trainable = False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"KPw8Lzra5_T9"},"source":["\n","\n","Декодер/апсемплер это просто серия апсемпл блоков имплементированнхы в TensorFlow examples."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"p0ZbfywEbZpJ","colab":{}},"source":["up_stack = [\n","    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n","    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n","    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n","    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"45HByxpVtrPF","colab":{}},"source":["def unet_model(output_channels):\n","  inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n","  x = inputs\n","\n","  # Downsampling through the model\n","  skips = down_stack(x)\n","  x = skips[-1]\n","  skips = reversed(skips[:-1])\n","\n","  # Upsampling and establishing the skip connections\n","  for up, skip in zip(up_stack, skips):\n","    x = up(x)\n","    concat = tf.keras.layers.Concatenate()\n","    x = concat([x, skip])\n","\n","  # This is the last layer of the model\n","  last = tf.keras.layers.Conv2DTranspose(\n","      output_channels, 3, strides=2,\n","      padding='same')  #64x64 -> 128x128\n","\n","  x = last(x)\n","\n","  return tf.keras.Model(inputs=inputs, outputs=x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"j0DGH_4T0VYn"},"source":["## Тренировка модели\n","Now, all that is left to do is to compile and train the model. The loss being used here is `losses.SparseCategoricalCrossentropy(from_logits=True)`. The reason to use this loss function is because the network is trying to assign each pixel a label, just like multi-class prediction. In the true segmentation mask, each pixel has either a {0,1,2}. The network here is outputting three channels. Essentially, each channel is trying to learn to predict a class, and `losses.SparseCategoricalCrossentropy(from_logits=True)` is the recommended loss for \n","such a scenario. Using the output of the network, the label assigned to the pixel is the channel with the highest value. This is what the create_mask function is doing.\n","\n","Теперь, все что осталось это скомпилировать модель и начать процесс ее тренировки. Loss-функция, которую будем использовать - `losses.SparseCategoricalCrossentropy(from_logits=True)`. Причина использования данной loss-функции заключается в том, что нейросеть пытается назначить каждому пикселю лейбл, также как в задачах предсказания класса. Для модели в которой 3 каннала каждый из которых пытается предсказать класс `losses.SparseCategoricalCrossentropy(from_logits=True)` обычно также рекомендуется.\n","На выходе нейросети каждому пикселю назначается лейбл с наибольшим значением. Это то, что делает функция create_mask.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6he36HK5uKAc","colab":{}},"source":["model = unet_model(OUTPUT_CHANNELS)\n","model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xVMzbIZLcyEF"},"source":["Посмотрим на получившуюся архитектуру модели."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sw82qF1Gcovr","colab":{}},"source":["tf.keras.utils.plot_model(model, show_shapes=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Tc3MiEO2twLS"},"source":["\n","Давайте попробуем сделать предсказание с помощью нашей модели до того как началось обучение."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UwvIKLZPtxV_","colab":{}},"source":["def create_mask(pred_mask):\n","  pred_mask = tf.argmax(pred_mask, axis=-1)\n","  pred_mask = pred_mask[..., tf.newaxis]\n","  return pred_mask[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YLNsrynNtx4d","colab":{}},"source":["def show_predictions(dataset=None, num=1):\n","  if dataset:\n","    for image, mask in dataset.take(num):\n","      pred_mask = model.predict(image)\n","      display([image[0], mask[0], create_mask(pred_mask)])\n","  else:\n","    display([sample_image, sample_mask,\n","             create_mask(model.predict(sample_image[tf.newaxis, ...]))])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"X_1CC0T4dho3","colab":{}},"source":["show_predictions()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"22AyVYWQdkgk"},"source":["\n","\n","Давайте осуществлять мониторинг того как улучшается работа модели в процессе обучения. Для завершения этой задачи callback функция определена ниже."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wHrHsqijdmL6","colab":{}},"source":["class DisplayCallback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs=None):\n","    clear_output(wait=True)\n","    show_predictions()\n","    print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"StKDH_B9t4SD","colab":{}},"source":["EPOCHS = 5 # увеличьте при необходимости\n","VAL_SUBSPLITS = 5\n","VALIDATION_STEPS = info.splits['test'].num_examples//BATCH_SIZE//VAL_SUBSPLITS\n","\n","model_history = model.fit(train_dataset, epochs=EPOCHS,\n","                          steps_per_epoch=STEPS_PER_EPOCH,\n","                          validation_steps=VALIDATION_STEPS,\n","                          validation_data=test_dataset,\n","                          callbacks=[DisplayCallback()])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"P_mu0SAbt40Q","colab":{}},"source":["loss = model_history.history['loss']\n","val_loss = model_history.history['val_loss']\n","\n","epochs = range(EPOCHS)\n","\n","plt.figure()\n","plt.plot(epochs, loss, 'r', label='Training loss')\n","plt.plot(epochs, val_loss, 'bo', label='Validation loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss Value')\n","plt.ylim([0, 1])\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"unP3cnxo_N72"},"source":["## Make predictions"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7BVXldSo-0mW"},"source":["Давайте сделаем несколько предсказаний. Для экономии времени использовалось небольшое количество эпох, но вы можете его увеличить для того чтобы модель давала более точные результаты."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ikrzoG24qwf5","colab":{}},"source":["show_predictions(test_dataset, 3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"R24tahEqmSCk"},"source":["## Практическое задание\n","\n","<ol>\n","    <li>Попробуйте обучить нейронную сеть U-Net на любом другом датасете. \n","        Опишите в комментарии к уроку - какой результата вы добились от нейросети? Что помогло вам улучшить ее точность?\n","    </li>\n","    <li>*Попробуйте свои силы в задаче Carvana на Kaggle - https://www.kaggle.com/c/carvana-image-masking-challenge/overview</li>\n","    <li>*Сделайте свою реализацию U-Net на TensorFlow</li>\n","</ol>"]},{"cell_type":"markdown","metadata":{"id":"0X8AzfIoIOo8","colab_type":"text"},"source":["## Дополнительные материалы\n","\n","<ol>\n","    <li>Оригинальная научная статья по FCN - https://arxiv.org/pdf/1411.4038.pdf</li>\n","    <li>Оригинальная научная статья по SegNet - https://arxiv.org/pdf/1511.00561.pdf</li>\n","    <li>Оригинальная научная статья по U-Net - https://arxiv.org/pdf/1505.04597.pdf</li>\n","     <li>Оригинальная научная статья по FPN - https://arxiv.org/pdf/1612.03144.pdf</li>\n","     <li>Оригинальная научная статья по Mask R-CNN - https://arxiv.org/pdf/2001.05566.pdf</li>\n","     <li> Научная статья с обзором отрасли сегментации изображений с помощью глубокого обучения - https://arxiv.org/pdf/2001.05566.pdf</li>\n","</ol>"]},{"cell_type":"markdown","metadata":{"id":"NwgdptHrIOo-","colab_type":"text"},"source":["## Используемая литература \n","\n","Для подготовки данного методического пособия были использованы следующие ресурсы:\n","<ol>\n","    <li>https://www.tensorflow.org/tutorials/images/segmentation</li>\n","    <li>Image Segmentation Using Deep Learning: A Survey. Shervin Minaee и др. 15 Jan 2020</li>\n","    <li>Mask R-CNN, Kaiming He и др. 24 янв. 2018 г.</li>\n","    <li>https://blog.athelas.com/a-brief-history-of-cnns-in-image-segmentation-from-r-cnn-to-mask-r-cnn-34ea83205de4</li>\n","    <li>Википедия</li>  \n","</ol>"]}]}